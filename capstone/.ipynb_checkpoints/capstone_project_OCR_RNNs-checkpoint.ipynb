{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical character recognition using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "URL_PATH = 'http://ai.stanford.edu/~btaskar/ocr/letter.data.gz'\n",
    "DOWNLOADED_FILENAME = 'letter.data.gz'\n",
    "\n",
    "def download_data():\n",
    "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(URL_PATH, DOWNLOADED_FILENAME)\n",
    "    \n",
    "    print'Found and verified file from this path: ', URL_PATH\n",
    "    print'Downloaded file: ', DOWNLOADED_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file from this path:  http://ai.stanford.edu/~btaskar/ocr/letter.data.gz\n",
      "Downloaded file:  letter.data.gz\n"
     ]
    }
   ],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_lines():\n",
    "    with gzip.open(DOWNLOADED_FILENAME, 'rt') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        lines = list(reader)\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lines = read_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " 'm',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52152"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels(lines):\n",
    "    lines = sorted(lines, key=lambda x: int(x[0]))\n",
    "    data, target = [], []\n",
    "    \n",
    "    next_id = -1\n",
    "    \n",
    "    word = []\n",
    "    word_pixels = []\n",
    "\n",
    "    for line in lines:\n",
    "         # The index for the next_id column\n",
    "        next_id = int(line[2])\n",
    "\n",
    "        # An image for a single character, reshaped\n",
    "        pixels = np.array([int(x) for x in line[6:134]])\n",
    "        pixels = pixels.reshape((16, 8))\n",
    "        \n",
    "        # Word pixels are a list of 16x8 images which form a single word\n",
    "        word_pixels.append(pixels)\n",
    "        \n",
    "        # Append together the characters which make up a word\n",
    "        word.append(line[1])\n",
    "        \n",
    "        if next_id == -1:\n",
    "            data.append(word_pixels)\n",
    "            target.append(word) \n",
    "            word = []\n",
    "            word_pixels = []\n",
    "\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data, target = get_features_labels(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### The total number of words in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 6877)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### All words lengths should be the same\n",
    "\n",
    "* Get every word to be the same length as the longest word in our dataset\n",
    "* Pad the words with empty characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pad_features_labels(data, target):    \n",
    "    max_length = max(len(x) for x in target)\n",
    "    \n",
    "    # Set up image representations for the empty string (all pixels set to 0)\n",
    "    padding = np.zeros((16, 8))\n",
    "\n",
    "    # Pad the image data with the empty string images\n",
    "    data = [x + ([padding] * (max_length - len(x))) for x in data]\n",
    "    \n",
    "    # Pad the words with empty string characters\n",
    "    target = [x + ([''] * (max_length - len(x))) for x in target]\n",
    "    \n",
    "    return np.array(data), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "padded_data, padded_target = pad_features_labels(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n",
       "       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', '']], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n",
       "       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', '']], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target[200:210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### The length of each sequence\n",
    "\n",
    "We've padded all words so that their lengths are all equal to the length of the longest word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_length = len(padded_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Tensor shape\n",
    "\n",
    "* 6877 words\n",
    "* Each word padded to have 14 characters\n",
    "* Each character represented by 16x8 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, 16, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, -1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape[:2] + (-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reshaped_data = padded_data.reshape(padded_data.shape[:2] + (-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reshape the data so the image is a 1-D array of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Tensor shape\n",
    "\n",
    "* 6877 words\n",
    "* Each an array with 14 characters (padded with empty strings as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### One-hot representation\n",
    "\n",
    "* Each character has a feature vector of 26 (only lower case characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6877, 14, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target.shape + (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_hot_target = np.zeros(padded_target.shape + (26,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Numpy.ndenumerate is a way to get all indices needed to access elements of a matrix\n",
    "<pre>\n",
    "a = numpy.array([[1,2],[3,4],[5,6]])\n",
    "for (x,y), value in numpy.ndenumerate(a):\n",
    "  print x,y \n",
    "</pre>\n",
    " \n",
    "0 0 <br>\n",
    "0 1 <br>\n",
    "1 0 <br>\n",
    "1 1 <br>\n",
    "2 0 <br>\n",
    "2 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, letter in np.ndenumerate(padded_target):\n",
    "    if letter:\n",
    "        one_hot_target[index][ord(letter) - ord('a')] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### One-hot representation of the letter 'o'\n",
    "\n",
    "* The letter 'o' represented by a 1 at the 14th index \n",
    "* Index positions start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_target[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(reshaped_data))\n",
    "\n",
    "shuffled_data = reshaped_data[shuffled_indices]\n",
    "shuffled_target = one_hot_target[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split = int(0.66 * len(shuffled_data))\n",
    "\n",
    "train_data = shuffled_data[:split]\n",
    "train_target = shuffled_target[:split]\n",
    "\n",
    "test_data = shuffled_data[split:]\n",
    "test_target = shuffled_target[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538, 14, 128)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, num_steps, num_inputs = train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538, 14, 26)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = train_target.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, [None, num_steps, num_inputs])\n",
    "\n",
    "y = tf.placeholder(tf.float64, [None, num_steps, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Sequence length calculation\n",
    "\n",
    "*['How', 'are', 'you', 'doing'] ==> [14, 14, 14, 14] ==> [3, 3, 3, 5]*\n",
    " \n",
    " The actual length of each word (without the padding) in the input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All real characters will have a max value of 1, padded characters will be represented by 0s\n",
    "used = tf.sign(tf.reduce_max(tf.abs(X), reduction_indices=2))\n",
    "\n",
    "# Sum up the number of real characters for each word\n",
    "length = tf.reduce_sum(used, reduction_indices=1)\n",
    "sequence_length = tf.cast(length, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(?,) dtype=int32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### RNN for training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_neurons = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.GRUCell(num_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### *sequence_length* is the length of the valid input for each batch\n",
    "\n",
    "Included to improve accuracy and not for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float64, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(300)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Shared softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([num_neurons, num_classes], stddev=0.01, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bias = tf.Variable(tf.constant(0.1, shape=[num_classes], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flattened_output = tf.reshape(output, [-1, num_neurons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 300) dtype=float64>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(flattened_output, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits_reshaped = tf.reshape(logits, [-1, num_steps, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-54-6b0d07fd5f9b>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Error calculation\n",
    "\n",
    "* For every word calculate how many of the characters we predicted correctly\n",
    "* Use the mask to not consider (leave out) the padded characters on which our prediction was wrong\n",
    "* Find the fraction of each word where we made mistakes in our character prediction\n",
    "* Find the average fraction of each word that were mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(\n",
    "            tf.argmax(y, 2), tf.argmax(logits_reshaped, 2))\n",
    "mistakes = tf.cast(mistakes, tf.float64)\n",
    "mask = tf.sign(tf.reduce_max(tf.abs(y), reduction_indices=2))\n",
    "mistakes *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mistakes = tf.reduce_sum(mistakes, reduction_indices=1)\n",
    "mistakes /= tf.cast(sequence_length, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error = tf.reduce_mean(mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gradient = optimizer.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimize = optimizer.apply_gradients(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batched(data, target, batch_size):\n",
    "    epoch = 0\n",
    "    offset = 0\n",
    "    while True:\n",
    "        old_offset = offset\n",
    "        offset = (offset + batch_size) % (target.shape[0] - batch_size)\n",
    "\n",
    "        # Offset wrapped around to the beginning so new epoch\n",
    "        if offset < old_offset:\n",
    "            # New epoch, need to shuffle data\n",
    "            shuffled_indices = np.random.permutation(len(data))\n",
    "            \n",
    "            data = data[shuffled_indices]\n",
    "            target = target[shuffled_indices]\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "        batch_data = data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        batch_target = target[offset:(offset + batch_size), :]\n",
    "\n",
    "        yield batch_data, batch_target, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "batches = batched(train_data, train_target, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 96.507937%\n",
      "2: 94.188312%\n",
      "3: 98.202686%\n",
      "4: 99.166667%\n",
      "5: 97.230159%\n",
      "6: 97.515873%\n",
      "7: 99.375000%\n",
      "8: 96.750000%\n",
      "9: 97.989899%\n",
      "10: 94.434829%\n",
      "11: 94.657051%\n",
      "12: 94.795635%\n",
      "13: 96.041667%\n",
      "14: 95.708333%\n",
      "15: 96.942280%\n",
      "16: 96.013709%\n",
      "17: 91.539627%\n",
      "18: 90.376984%\n",
      "19: 94.045455%\n",
      "20: 97.531746%\n",
      "21: 95.351190%\n",
      "22: 90.063492%\n",
      "23: 91.362734%\n",
      "24: 93.755952%\n",
      "25: 86.968323%\n",
      "26: 93.025794%\n",
      "27: 94.507937%\n",
      "28: 92.019481%\n",
      "29: 93.936508%\n",
      "30: 92.494048%\n",
      "31: 93.974026%\n",
      "32: 91.010046%\n",
      "33: 91.984127%\n",
      "34: 91.887210%\n",
      "35: 96.136142%\n",
      "36: 87.591270%\n",
      "37: 92.419261%\n",
      "38: 86.050866%\n",
      "39: 90.924603%\n",
      "40: 91.439103%\n",
      "41: 93.244048%\n",
      "42: 96.869658%\n",
      "43: 87.898268%\n",
      "44: 92.257881%\n",
      "45: 88.691919%\n",
      "46: 91.973485%\n",
      "47: 84.680986%\n",
      "48: 86.155067%\n",
      "49: 89.682540%\n",
      "50: 91.529526%\n",
      "51: 89.920455%\n",
      "52: 90.040598%\n",
      "53: 90.514319%\n",
      "54: 86.238095%\n",
      "55: 86.718198%\n",
      "56: 90.807179%\n",
      "57: 87.794913%\n",
      "58: 87.966880%\n",
      "59: 88.946553%\n",
      "60: 86.400683%\n",
      "61: 92.625000%\n",
      "62: 88.965146%\n",
      "63: 90.847527%\n",
      "64: 92.705128%\n",
      "65: 89.140873%\n",
      "66: 87.197330%\n",
      "67: 87.297536%\n",
      "68: 89.076188%\n",
      "69: 85.725427%\n",
      "70: 90.220613%\n",
      "71: 79.124709%\n",
      "72: 83.466644%\n",
      "73: 93.642857%\n",
      "74: 86.884921%\n",
      "75: 85.948052%\n",
      "76: 83.978785%\n",
      "77: 85.676227%\n",
      "78: 87.381854%\n",
      "79: 87.655664%\n",
      "80: 88.944028%\n",
      "81: 89.457973%\n",
      "82: 82.823968%\n",
      "83: 89.444999%\n",
      "84: 91.324856%\n",
      "85: 87.897436%\n",
      "86: 83.168415%\n",
      "87: 79.318362%\n",
      "88: 85.308442%\n",
      "89: 87.813992%\n",
      "90: 82.778694%\n",
      "91: 87.858586%\n",
      "92: 83.353272%\n",
      "93: 84.802808%\n",
      "94: 87.010073%\n",
      "95: 83.404762%\n",
      "96: 84.718809%\n",
      "97: 88.643162%\n",
      "98: 90.183150%\n",
      "99: 79.100108%\n",
      "100: 81.043956%\n",
      "101: 88.756563%\n",
      "102: 82.134380%\n",
      "103: 73.028860%\n",
      "104: 81.751776%\n",
      "105: 82.073107%\n",
      "106: 79.553571%\n",
      "107: 76.779956%\n",
      "108: 79.359502%\n",
      "109: 85.881632%\n",
      "110: 76.465576%\n",
      "111: 85.722777%\n",
      "112: 79.979618%\n",
      "113: 86.619547%\n",
      "114: 82.074925%\n",
      "115: 88.611666%\n",
      "116: 80.342713%\n",
      "117: 82.640873%\n",
      "118: 88.732448%\n",
      "119: 88.466950%\n",
      "120: 73.682179%\n",
      "121: 75.154762%\n",
      "122: 78.730228%\n",
      "123: 81.230589%\n",
      "124: 83.673882%\n",
      "125: 77.813645%\n",
      "126: 77.073912%\n",
      "127: 82.623016%\n",
      "128: 81.704365%\n",
      "129: 79.790959%\n",
      "130: 71.904554%\n",
      "131: 73.660173%\n",
      "132: 70.849206%\n",
      "133: 78.097597%\n",
      "134: 81.871642%\n",
      "135: 72.626596%\n",
      "136: 78.459055%\n",
      "137: 76.712759%\n",
      "138: 75.930195%\n",
      "139: 77.739538%\n",
      "140: 76.351648%\n",
      "141: 70.665904%\n",
      "142: 73.058455%\n",
      "143: 70.757035%\n",
      "144: 59.348513%\n",
      "145: 69.038253%\n",
      "146: 69.481241%\n",
      "147: 66.897200%\n",
      "148: 66.893579%\n",
      "149: 67.842713%\n",
      "150: 73.510240%\n",
      "151: 70.221501%\n",
      "152: 63.959873%\n",
      "153: 66.703644%\n",
      "154: 59.541375%\n",
      "155: 70.554945%\n",
      "156: 60.011183%\n",
      "157: 60.852814%\n",
      "158: 68.708528%\n",
      "159: 54.267857%\n",
      "160: 57.216991%\n",
      "161: 61.110181%\n",
      "162: 54.704726%\n",
      "163: 54.263431%\n",
      "164: 49.801671%\n",
      "165: 50.161644%\n",
      "166: 60.162546%\n",
      "167: 52.617091%\n",
      "168: 49.427933%\n",
      "169: 48.265873%\n",
      "170: 55.944944%\n",
      "171: 45.471889%\n",
      "172: 51.501984%\n",
      "173: 46.340826%\n",
      "174: 48.889139%\n",
      "175: 42.592907%\n",
      "176: 41.731602%\n",
      "177: 46.382312%\n",
      "178: 40.430403%\n",
      "179: 41.165751%\n",
      "180: 39.788767%\n",
      "181: 45.775336%\n",
      "182: 44.531538%\n",
      "183: 33.198094%\n",
      "184: 46.646104%\n",
      "185: 33.376068%\n",
      "186: 41.736389%\n",
      "187: 39.720044%\n",
      "188: 32.397575%\n",
      "189: 53.125194%\n",
      "190: 42.720058%\n",
      "191: 39.534188%\n",
      "192: 35.625513%\n",
      "193: 36.204212%\n",
      "194: 37.263209%\n",
      "195: 43.914683%\n",
      "196: 29.423687%\n",
      "197: 18.139499%\n",
      "198: 33.339646%\n",
      "199: 34.700314%\n",
      "200: 29.979548%\n",
      "201: 37.776696%\n",
      "202: 40.619949%\n",
      "203: 45.633242%\n",
      "204: 43.127165%\n",
      "205: 29.529762%\n",
      "206: 40.844905%\n",
      "207: 41.399573%\n",
      "208: 33.464286%\n",
      "209: 35.648768%\n",
      "210: 38.170635%\n",
      "211: 29.251984%\n",
      "212: 36.666667%\n",
      "213: 30.245310%\n",
      "214: 34.154762%\n",
      "215: 32.352647%\n",
      "216: 26.767399%\n",
      "217: 28.486111%\n",
      "218: 28.579060%\n",
      "219: 25.878816%\n",
      "220: 25.168498%\n",
      "221: 18.359890%\n",
      "222: 29.154151%\n",
      "223: 41.281025%\n",
      "224: 24.183303%\n",
      "225: 25.482323%\n",
      "226: 25.548077%\n",
      "227: 27.769841%\n",
      "228: 16.318543%\n",
      "229: 26.742396%\n",
      "230: 23.205988%\n",
      "231: 21.023199%\n",
      "232: 22.563672%\n",
      "233: 25.851732%\n",
      "234: 32.558358%\n",
      "235: 26.097791%\n",
      "236: 16.558664%\n",
      "237: 35.259241%\n",
      "238: 31.849206%\n",
      "239: 18.712413%\n",
      "240: 18.962302%\n",
      "241: 32.679029%\n",
      "242: 18.197802%\n",
      "243: 26.238276%\n",
      "244: 12.512266%\n",
      "245: 26.253538%\n",
      "246: 21.700549%\n",
      "247: 27.722708%\n",
      "248: 14.040806%\n",
      "249: 21.667388%\n",
      "250: 21.472222%\n",
      "251: 26.426573%\n",
      "252: 22.968975%\n",
      "253: 18.004870%\n",
      "254: 20.524420%\n",
      "255: 17.564866%\n",
      "256: 28.078824%\n",
      "257: 20.242785%\n",
      "258: 20.777778%\n",
      "259: 20.578630%\n",
      "260: 22.225580%\n",
      "261: 14.798521%\n",
      "262: 17.981643%\n",
      "263: 23.320846%\n",
      "264: 27.242605%\n",
      "265: 14.252498%\n",
      "266: 21.476190%\n",
      "267: 26.787546%\n",
      "268: 20.895965%\n",
      "269: 21.861111%\n",
      "270: 24.131854%\n",
      "271: 23.914405%\n",
      "272: 22.659507%\n",
      "273: 13.178322%\n",
      "274: 14.751984%\n",
      "275: 21.192460%\n",
      "276: 17.290806%\n",
      "277: 15.976010%\n",
      "278: 17.980880%\n",
      "279: 13.710165%\n",
      "280: 19.240079%\n",
      "281: 36.763931%\n",
      "282: 19.791667%\n",
      "283: 15.305556%\n",
      "284: 26.754412%\n",
      "285: 12.089161%\n",
      "286: 16.225191%\n",
      "287: 15.021465%\n",
      "288: 17.145188%\n",
      "289: 20.297619%\n",
      "290: 16.025253%\n",
      "291: 15.229396%\n",
      "292: 16.106061%\n",
      "293: 26.259921%\n",
      "294: 12.855339%\n",
      "295: 15.851648%\n",
      "296: 22.273837%\n",
      "297: 17.547675%\n",
      "298: 7.958389%\n",
      "299: 15.865981%\n",
      "300: 25.508755%\n",
      "301: 23.141331%\n",
      "302: 15.671537%\n",
      "303: 27.569278%\n",
      "304: 18.478535%\n",
      "305: 14.841686%\n",
      "306: 14.571429%\n",
      "307: 13.025253%\n",
      "308: 15.826035%\n",
      "309: 10.065351%\n",
      "310: 13.729548%\n",
      "311: 22.780123%\n",
      "312: 14.164683%\n",
      "313: 20.779762%\n",
      "314: 17.538462%\n",
      "315: 15.625722%\n",
      "316: 19.986569%\n",
      "317: 15.114164%\n",
      "318: 13.096154%\n",
      "319: 23.346667%\n",
      "320: 14.315171%\n",
      "321: 16.220779%\n",
      "322: 11.041847%\n",
      "323: 13.078755%\n",
      "324: 14.702006%\n",
      "325: 17.620851%\n",
      "326: 16.416417%\n",
      "327: 15.881716%\n",
      "328: 9.847375%\n",
      "329: 10.331349%\n",
      "330: 16.797980%\n",
      "331: 18.112193%\n",
      "332: 18.444014%\n",
      "333: 16.160867%\n",
      "334: 18.373016%\n",
      "335: 6.706349%\n",
      "336: 6.799659%\n",
      "337: 18.525794%\n",
      "338: 22.003358%\n",
      "339: 15.850039%\n",
      "340: 15.635642%\n",
      "341: 20.724206%\n",
      "342: 16.533730%\n",
      "343: 14.427184%\n",
      "344: 15.399892%\n",
      "345: 16.285714%\n",
      "346: 17.645910%\n",
      "347: 14.003968%\n",
      "348: 13.118437%\n",
      "349: 7.495782%\n",
      "350: 11.022644%\n",
      "351: 11.871420%\n",
      "352: 13.142552%\n",
      "353: 13.148504%\n",
      "354: 14.845238%\n",
      "355: 12.791292%\n",
      "356: 17.599928%\n",
      "357: 9.397006%\n",
      "358: 11.213675%\n",
      "359: 19.223291%\n",
      "360: 8.605700%\n",
      "361: 4.144841%\n",
      "362: 9.250153%\n",
      "363: 8.623252%\n",
      "364: 18.363095%\n",
      "365: 23.163045%\n",
      "366: 10.456710%\n",
      "367: 9.209402%\n",
      "368: 16.873377%\n",
      "369: 14.601190%\n",
      "370: 13.783425%\n",
      "371: 14.438853%\n",
      "372: 17.318529%\n",
      "373: 16.529762%\n",
      "374: 12.397894%\n",
      "375: 10.380051%\n",
      "376: 14.630952%\n",
      "377: 9.583333%\n",
      "378: 8.869464%\n",
      "379: 11.458028%\n",
      "380: 8.265873%\n",
      "381: 11.166056%\n",
      "382: 10.521520%\n",
      "383: 13.631729%\n",
      "384: 15.968615%\n",
      "385: 15.242965%\n",
      "386: 9.263584%\n",
      "387: 19.394536%\n",
      "388: 17.230339%\n",
      "389: 9.198773%\n",
      "390: 12.421898%\n",
      "391: 11.247114%\n",
      "392: 12.213675%\n",
      "393: 12.430556%\n",
      "394: 11.997100%\n",
      "395: 6.912879%\n",
      "396: 5.179820%\n",
      "397: 11.180556%\n",
      "398: 9.992785%\n",
      "399: 14.387085%\n",
      "400: 12.825092%\n",
      "401: 16.577381%\n",
      "402: 11.222222%\n",
      "403: 13.961691%\n",
      "404: 13.372766%\n",
      "405: 5.986472%\n",
      "406: 18.289530%\n",
      "407: 11.237596%\n",
      "408: 17.734127%\n",
      "409: 9.293221%\n",
      "410: 19.497100%\n",
      "411: 6.287393%\n",
      "412: 7.428571%\n",
      "413: 20.119048%\n",
      "414: 15.267857%\n",
      "415: 16.711455%\n",
      "416: 10.527778%\n",
      "417: 11.943889%\n",
      "418: 4.357143%\n",
      "419: 14.702312%\n",
      "420: 16.589286%\n",
      "421: 13.275974%\n",
      "422: 8.128843%\n",
      "423: 8.293651%\n",
      "424: 18.709416%\n",
      "425: 12.561383%\n",
      "426: 11.537698%\n",
      "427: 16.347403%\n",
      "428: 8.322511%\n",
      "429: 10.727564%\n",
      "430: 8.386475%\n",
      "431: 15.407509%\n",
      "432: 9.911477%\n",
      "433: 0.833333%\n",
      "434: 17.255952%\n",
      "435: 9.551587%\n",
      "436: 7.533605%\n",
      "437: 12.522727%\n",
      "438: 13.269897%\n",
      "439: 7.714286%\n",
      "440: 13.946997%\n",
      "441: 7.400544%\n",
      "442: 8.849206%\n",
      "443: 11.083333%\n",
      "444: 9.670635%\n",
      "445: 10.168651%\n",
      "446: 9.486652%\n",
      "447: 6.548687%\n",
      "448: 13.787698%\n",
      "449: 14.464286%\n",
      "450: 6.222222%\n",
      "451: 10.184885%\n",
      "452: 4.603175%\n",
      "453: 9.001082%\n",
      "454: 8.275058%\n",
      "455: 6.650794%\n",
      "456: 10.241453%\n",
      "457: 10.315476%\n",
      "458: 14.055556%\n",
      "459: 5.016053%\n",
      "460: 9.672494%\n",
      "461: 5.940171%\n",
      "462: 6.236111%\n",
      "463: 6.136780%\n",
      "464: 10.866633%\n",
      "465: 4.603175%\n",
      "466: 12.184524%\n",
      "467: 5.634921%\n",
      "468: 6.677836%\n",
      "469: 8.559524%\n",
      "470: 11.098901%\n",
      "471: 10.990079%\n",
      "472: 10.587302%\n",
      "473: 11.949786%\n",
      "474: 7.797494%\n",
      "475: 5.507506%\n",
      "476: 10.676948%\n",
      "477: 7.783730%\n",
      "478: 8.130342%\n",
      "479: 5.509615%\n",
      "480: 9.589466%\n",
      "481: 10.589744%\n",
      "482: 14.880342%\n",
      "483: 4.672619%\n",
      "484: 5.519231%\n",
      "485: 5.972222%\n",
      "486: 5.057540%\n",
      "487: 11.783730%\n",
      "488: 3.857143%\n",
      "489: 9.891414%\n",
      "490: 3.446789%\n",
      "491: 6.658911%\n",
      "492: 7.585193%\n",
      "493: 7.569444%\n",
      "494: 6.244048%\n",
      "495: 10.581460%\n",
      "496: 6.089286%\n",
      "497: 7.148990%\n",
      "498: 3.797619%\n",
      "499: 16.431624%\n",
      "500: 7.936508%\n",
      "501: 16.621212%\n",
      "502: 7.287879%\n",
      "503: 7.936508%\n",
      "504: 8.414918%\n",
      "505: 8.205739%\n",
      "506: 10.958333%\n",
      "507: 5.691850%\n",
      "508: 8.541667%\n",
      "509: 6.858697%\n",
      "510: 7.261905%\n",
      "511: 7.739927%\n",
      "512: 6.111111%\n",
      "513: 9.308081%\n",
      "514: 9.285714%\n",
      "515: 2.019716%\n",
      "516: 8.936869%\n",
      "517: 5.626679%\n",
      "518: 6.958333%\n",
      "519: 8.690476%\n",
      "520: 17.218254%\n",
      "521: 13.642247%\n",
      "522: 7.072497%\n",
      "523: 2.847222%\n",
      "524: 12.093407%\n",
      "525: 7.118437%\n",
      "526: 5.829060%\n",
      "527: 3.787393%\n",
      "528: 10.583333%\n",
      "529: 5.712302%\n",
      "530: 9.105339%\n",
      "531: 2.682540%\n",
      "532: 5.861111%\n",
      "533: 3.722222%\n",
      "534: 10.618326%\n",
      "535: 5.352564%\n",
      "536: 6.446123%\n",
      "537: 5.635101%\n",
      "538: 11.300144%\n",
      "539: 11.375000%\n",
      "540: 3.329060%\n",
      "541: 12.551587%\n",
      "542: 5.005952%\n",
      "543: 9.472222%\n",
      "544: 3.388889%\n",
      "545: 1.944444%\n",
      "546: 11.061508%\n",
      "547: 7.222222%\n",
      "548: 7.981838%\n",
      "549: 4.228175%\n",
      "550: 18.706710%\n",
      "551: 11.425366%\n",
      "552: 4.650794%\n",
      "553: 7.728175%\n",
      "554: 11.629329%\n",
      "555: 12.907162%\n",
      "556: 11.598291%\n",
      "557: 9.579545%\n",
      "558: 11.797619%\n",
      "559: 6.568182%\n",
      "560: 6.190476%\n",
      "561: 8.398504%\n",
      "562: 8.299062%\n",
      "563: 7.519841%\n",
      "564: 2.435897%\n",
      "565: 7.666667%\n",
      "566: 6.555556%\n",
      "567: 15.746032%\n",
      "568: 7.460317%\n",
      "569: 7.706349%\n",
      "570: 7.436508%\n",
      "571: 6.440657%\n",
      "572: 13.936508%\n",
      "573: 8.095238%\n",
      "574: 5.335498%\n",
      "575: 15.103175%\n",
      "576: 10.089646%\n",
      "577: 12.565476%\n",
      "578: 19.920635%\n",
      "579: 10.261905%\n",
      "580: 9.833333%\n",
      "581: 13.944444%\n",
      "582: 9.930556%\n",
      "583: 5.944444%\n",
      "584: 5.888889%\n",
      "585: 9.742063%\n",
      "586: 6.006313%\n",
      "587: 6.821789%\n",
      "588: 2.483516%\n",
      "589: 5.597222%\n",
      "590: 8.402778%\n",
      "591: 7.394841%\n",
      "592: 5.454545%\n",
      "593: 7.470238%\n",
      "594: 8.148810%\n",
      "595: 5.714286%\n",
      "596: 7.609668%\n",
      "597: 1.111111%\n",
      "598: 7.863636%\n",
      "599: 6.334707%\n",
      "600: 7.925144%\n",
      "601: 10.133089%\n",
      "602: 5.555556%\n",
      "603: 10.047619%\n",
      "604: 5.049534%\n",
      "605: 7.458333%\n",
      "606: 2.919192%\n",
      "607: 9.027778%\n",
      "608: 8.800144%\n",
      "609: 5.125000%\n",
      "610: 2.963980%\n",
      "611: 4.871032%\n",
      "612: 6.057900%\n",
      "613: 12.553571%\n",
      "614: 9.666667%\n",
      "615: 8.773810%\n",
      "616: 10.214286%\n",
      "617: 5.752165%\n",
      "618: 5.196429%\n",
      "619: 6.718615%\n",
      "620: 8.914918%\n",
      "621: 6.885101%\n",
      "622: 9.902778%\n",
      "623: 7.322192%\n",
      "624: 11.990079%\n",
      "625: 3.404942%\n",
      "626: 4.821429%\n",
      "627: 4.182900%\n",
      "628: 7.426740%\n",
      "629: 10.269536%\n",
      "630: 12.901154%\n",
      "631: 5.678932%\n",
      "632: 5.347222%\n",
      "633: 4.416667%\n",
      "634: 2.936508%\n",
      "635: 10.057234%\n",
      "636: 12.053571%\n",
      "637: 9.583333%\n",
      "638: 7.348901%\n",
      "639: 12.755952%\n",
      "640: 5.731838%\n",
      "641: 11.741758%\n",
      "642: 7.432234%\n",
      "643: 6.666667%\n",
      "644: 8.436508%\n",
      "645: 9.293040%\n",
      "646: 5.738095%\n",
      "647: 7.236111%\n",
      "648: 10.637973%\n",
      "649: 11.350941%\n",
      "650: 6.736111%\n",
      "651: 10.592949%\n",
      "652: 9.830614%\n",
      "653: 5.890568%\n",
      "654: 5.301282%\n",
      "655: 6.054945%\n",
      "656: 11.519231%\n",
      "657: 8.570998%\n",
      "658: 8.727869%\n",
      "659: 7.499695%\n",
      "660: 3.829545%\n",
      "661: 7.009615%\n",
      "662: 3.291667%\n",
      "663: 10.055556%\n",
      "664: 1.575092%\n",
      "665: 6.746753%\n",
      "666: 12.378968%\n",
      "667: 10.122586%\n",
      "668: 5.321123%\n",
      "669: 8.534799%\n",
      "670: 5.761905%\n",
      "671: 12.422314%\n",
      "672: 7.114164%\n",
      "673: 6.797314%\n",
      "674: 10.814214%\n",
      "675: 5.249084%\n",
      "676: 4.715659%\n",
      "677: 8.029942%\n",
      "678: 3.371212%\n",
      "679: 6.500000%\n",
      "680: 6.111111%\n",
      "681: 4.523810%\n",
      "682: 5.134921%\n",
      "683: 7.388889%\n",
      "684: 8.468254%\n",
      "685: 6.388889%\n",
      "686: 4.329365%\n",
      "687: 3.769841%\n",
      "688: 5.347222%\n",
      "689: 4.200758%\n",
      "690: 3.131313%\n",
      "691: 2.773504%\n",
      "692: 1.500000%\n",
      "693: 4.125000%\n",
      "694: 2.598901%\n",
      "695: 1.440171%\n",
      "696: 7.527778%\n",
      "697: 1.555556%\n",
      "698: 7.369048%\n",
      "699: 5.342949%\n",
      "700: 7.571123%\n",
      "701: 8.388889%\n",
      "702: 1.635101%\n",
      "703: 7.518093%\n",
      "704: 3.333333%\n",
      "705: 5.658120%\n",
      "706: 4.038462%\n",
      "707: 1.555556%\n",
      "708: 9.023504%\n",
      "709: 9.860195%\n",
      "710: 2.222222%\n",
      "711: 5.642857%\n",
      "712: 4.531136%\n",
      "713: 2.000000%\n",
      "714: 5.797980%\n",
      "715: 2.515568%\n",
      "716: 0.940171%\n",
      "717: 7.339286%\n",
      "718: 2.291667%\n",
      "719: 2.793831%\n",
      "720: 3.387446%\n",
      "721: 7.527778%\n",
      "722: 3.089286%\n",
      "723: 9.805556%\n",
      "724: 5.436508%\n",
      "725: 4.876068%\n",
      "726: 4.541667%\n",
      "727: 8.472222%\n",
      "728: 6.083333%\n",
      "729: 2.329545%\n",
      "730: 5.427350%\n",
      "731: 17.686508%\n",
      "732: 7.872711%\n",
      "733: 2.408425%\n",
      "734: 4.500000%\n",
      "735: 2.886905%\n",
      "736: 10.831349%\n",
      "737: 5.035409%\n",
      "738: 7.310897%\n",
      "739: 3.785714%\n",
      "740: 9.845599%\n",
      "741: 8.019841%\n",
      "742: 8.995726%\n",
      "743: 3.416667%\n",
      "744: 2.805556%\n",
      "745: 4.513889%\n",
      "746: 2.997586%\n",
      "747: 4.843434%\n",
      "748: 3.051282%\n",
      "749: 3.994228%\n",
      "750: 3.095238%\n",
      "751: 7.646520%\n",
      "752: 6.214286%\n",
      "753: 2.968254%\n",
      "754: 3.630952%\n",
      "755: 9.829365%\n",
      "756: 5.722222%\n",
      "757: 2.746212%\n",
      "758: 5.416667%\n",
      "759: 7.888889%\n",
      "760: 6.166667%\n",
      "761: 12.394231%\n",
      "762: 10.666667%\n",
      "763: 3.321429%\n",
      "764: 6.922314%\n",
      "765: 5.317460%\n",
      "766: 1.168831%\n",
      "767: 5.545635%\n",
      "768: 5.333333%\n",
      "769: 2.222222%\n",
      "770: 0.000000%\n",
      "771: 2.083333%\n",
      "772: 11.482018%\n",
      "773: 2.500000%\n",
      "774: 5.593434%\n",
      "775: 4.201770%\n",
      "776: 8.236347%\n",
      "777: 5.047619%\n",
      "778: 3.658911%\n",
      "779: 4.833333%\n",
      "780: 11.328283%\n",
      "781: 3.609127%\n",
      "782: 2.111111%\n",
      "783: 9.880952%\n",
      "784: 2.325397%\n",
      "785: 3.291667%\n",
      "786: 10.384615%\n",
      "787: 3.333333%\n",
      "788: 3.182720%\n",
      "789: 10.750000%\n",
      "790: 6.613276%\n",
      "791: 7.638278%\n",
      "792: 6.339286%\n",
      "793: 4.404762%\n",
      "794: 7.142857%\n",
      "795: 7.307720%\n",
      "796: 6.991453%\n",
      "797: 4.958333%\n",
      "798: 7.279457%\n",
      "799: 2.435897%\n",
      "800: 8.166667%\n",
      "801: 5.777778%\n",
      "802: 2.783605%\n",
      "803: 6.428571%\n",
      "804: 11.625000%\n",
      "805: 5.222222%\n",
      "806: 4.134615%\n",
      "807: 6.269841%\n",
      "808: 3.333333%\n",
      "809: 2.537879%\n",
      "810: 4.717949%\n",
      "811: 7.454726%\n",
      "812: 3.083333%\n",
      "813: 6.010101%\n",
      "814: 6.513889%\n",
      "815: 5.408120%\n",
      "816: 11.555556%\n",
      "817: 3.833333%\n",
      "818: 5.828283%\n",
      "819: 6.908120%\n",
      "820: 2.430556%\n",
      "821: 7.019716%\n",
      "822: 3.638889%\n",
      "823: 5.553571%\n",
      "824: 6.685897%\n",
      "825: 1.269841%\n",
      "826: 8.094017%\n",
      "827: 9.492063%\n",
      "828: 3.111111%\n",
      "829: 4.342949%\n",
      "830: 3.430736%\n",
      "831: 4.523810%\n",
      "832: 1.736111%\n",
      "833: 2.995726%\n",
      "834: 10.009671%\n",
      "835: 6.065476%\n",
      "836: 3.867244%\n",
      "837: 7.027778%\n",
      "838: 8.222222%\n",
      "839: 3.166667%\n",
      "840: 6.319444%\n",
      "841: 3.435065%\n",
      "842: 9.000000%\n",
      "843: 3.130342%\n",
      "844: 8.458333%\n",
      "845: 2.704545%\n",
      "846: 6.985806%\n",
      "847: 7.316850%\n",
      "848: 7.662393%\n",
      "849: 3.283730%\n",
      "850: 4.122711%\n",
      "851: 2.400794%\n",
      "852: 4.958333%\n",
      "853: 2.435897%\n",
      "854: 4.305556%\n",
      "855: 6.093434%\n",
      "856: 6.180556%\n",
      "857: 3.371212%\n",
      "858: 3.234127%\n",
      "859: 4.787879%\n",
      "860: 2.553571%\n",
      "861: 5.597403%\n",
      "862: 6.531746%\n",
      "863: 1.388889%\n",
      "864: 3.380952%\n",
      "865: 1.625000%\n",
      "866: 3.150183%\n",
      "867: 6.464646%\n",
      "868: 5.119048%\n",
      "869: 6.442641%\n",
      "870: 8.642857%\n",
      "871: 4.047619%\n",
      "872: 3.150183%\n",
      "873: 3.333333%\n",
      "874: 6.789683%\n",
      "875: 5.560897%\n",
      "876: 17.464286%\n",
      "877: 4.484127%\n",
      "878: 1.805556%\n",
      "879: 6.428571%\n",
      "880: 9.680556%\n",
      "881: 1.785714%\n",
      "882: 7.067460%\n",
      "883: 5.960498%\n",
      "884: 6.495726%\n",
      "885: 19.722222%\n",
      "886: 9.682540%\n",
      "887: 4.898990%\n",
      "888: 4.005952%\n",
      "889: 6.033730%\n",
      "890: 6.464646%\n",
      "891: 3.579365%\n",
      "892: 4.412879%\n",
      "893: 7.367063%\n",
      "894: 2.567155%\n",
      "895: 7.797619%\n",
      "896: 5.750000%\n",
      "897: 2.435897%\n",
      "898: 7.811869%\n",
      "899: 12.009615%\n",
      "900: 2.478355%\n",
      "901: 3.311508%\n",
      "902: 3.638889%\n",
      "903: 5.970696%\n",
      "904: 1.098901%\n",
      "905: 3.342949%\n",
      "906: 6.376679%\n",
      "907: 2.398990%\n",
      "908: 1.098901%\n",
      "909: 1.000000%\n",
      "910: 3.809524%\n",
      "911: 1.894841%\n",
      "912: 6.081710%\n",
      "913: 0.625000%\n",
      "914: 1.611111%\n",
      "915: 2.428571%\n",
      "916: 0.833333%\n",
      "917: 8.118437%\n",
      "918: 5.714286%\n",
      "919: 2.626679%\n",
      "920: 6.987790%\n",
      "921: 3.996212%\n",
      "922: 3.547619%\n",
      "923: 3.402778%\n",
      "924: 3.353175%\n",
      "925: 2.222222%\n",
      "926: 4.125000%\n",
      "927: 3.611111%\n",
      "928: 4.484127%\n",
      "929: 1.111111%\n",
      "930: 2.222222%\n",
      "931: 2.023810%\n",
      "932: 7.400794%\n",
      "933: 4.662698%\n",
      "934: 4.722222%\n",
      "935: 5.023810%\n",
      "936: 8.986111%\n",
      "937: 2.904762%\n",
      "938: 3.125000%\n",
      "939: 0.000000%\n",
      "940: 2.380342%\n",
      "941: 8.510101%\n",
      "942: 1.000000%\n",
      "943: 6.089286%\n",
      "944: 3.571429%\n",
      "945: 3.277778%\n",
      "946: 1.500000%\n",
      "947: 3.222222%\n",
      "948: 0.982143%\n",
      "949: 11.964286%\n",
      "950: 2.121212%\n",
      "951: 3.652958%\n",
      "952: 2.666667%\n",
      "953: 2.166667%\n",
      "954: 5.916667%\n",
      "955: 0.625000%\n",
      "956: 4.287879%\n",
      "957: 4.973901%\n",
      "958: 7.666667%\n",
      "959: 2.944444%\n",
      "960: 0.555556%\n",
      "961: 9.166667%\n",
      "962: 3.791667%\n",
      "963: 4.791667%\n",
      "964: 7.305250%\n",
      "965: 16.250000%\n",
      "966: 2.500000%\n",
      "967: 2.222222%\n",
      "968: 3.380952%\n",
      "969: 5.555556%\n",
      "970: 1.454545%\n",
      "971: 0.833333%\n",
      "972: 3.111111%\n",
      "973: 1.428571%\n",
      "974: 8.297494%\n",
      "975: 3.555556%\n",
      "976: 2.166667%\n",
      "977: 4.071123%\n",
      "978: 0.000000%\n",
      "979: 3.787879%\n",
      "980: 2.500000%\n",
      "981: 1.111111%\n",
      "982: 2.620726%\n",
      "983: 6.603175%\n",
      "984: 1.468254%\n",
      "985: 6.932234%\n",
      "986: 5.884615%\n",
      "987: 2.765568%\n",
      "988: 4.039683%\n",
      "989: 7.398810%\n",
      "990: 5.136905%\n",
      "991: 4.686508%\n",
      "992: 8.819444%\n",
      "993: 5.513889%\n",
      "994: 2.918706%\n",
      "995: 5.861111%\n",
      "996: 3.202076%\n",
      "997: 2.083333%\n",
      "998: 5.400794%\n",
      "999: 10.833333%\n",
      "1000: 3.436508%\n",
      "1001: 5.742244%\n",
      "1002: 5.260101%\n",
      "1003: 2.852869%\n",
      "1004: 4.375000%\n",
      "1005: 2.500000%\n",
      "1006: 2.291667%\n",
      "1007: 4.888889%\n",
      "1008: 4.130952%\n",
      "1009: 5.809524%\n",
      "1010: 1.801282%\n",
      "1011: 6.009615%\n",
      "1012: 3.833333%\n",
      "1013: 2.972222%\n",
      "1014: 2.083333%\n",
      "1015: 4.361111%\n",
      "1016: 4.134921%\n",
      "1017: 5.523990%\n",
      "1018: 5.103175%\n",
      "1019: 1.111111%\n",
      "1020: 1.541667%\n",
      "1021: 3.958333%\n",
      "1022: 8.408120%\n",
      "1023: 5.059524%\n",
      "1024: 1.055556%\n",
      "1025: 2.051282%\n",
      "1026: 4.027778%\n",
      "1027: 4.547619%\n",
      "1028: 2.606838%\n",
      "1029: 4.638889%\n",
      "1030: 1.717949%\n",
      "1031: 5.444444%\n",
      "1032: 1.884921%\n",
      "1033: 6.954365%\n",
      "1034: 3.770022%\n",
      "1035: 0.500000%\n",
      "1036: 2.579365%\n",
      "1037: 1.098901%\n",
      "1038: 4.224262%\n",
      "1039: 5.738151%\n",
      "1040: 3.333333%\n",
      "1041: 6.833333%\n",
      "1042: 2.889957%\n",
      "1043: 3.554945%\n",
      "1044: 2.523810%\n",
      "1045: 5.487179%\n",
      "1046: 4.166667%\n",
      "1047: 7.291667%\n",
      "1048: 3.430736%\n",
      "1049: 2.916667%\n",
      "1050: 5.122100%\n",
      "1051: 1.416667%\n",
      "1052: 2.634615%\n",
      "1053: 0.833333%\n",
      "1054: 3.260101%\n",
      "1055: 2.172494%\n",
      "1056: 6.709402%\n",
      "1057: 1.458333%\n",
      "1058: 2.666667%\n",
      "1059: 0.625000%\n",
      "1060: 3.394716%\n",
      "1061: 3.291667%\n",
      "1062: 2.519231%\n",
      "1063: 4.811203%\n",
      "1064: 12.022006%\n",
      "1065: 2.111111%\n",
      "1066: 8.769841%\n",
      "1067: 0.500000%\n",
      "1068: 4.672494%\n",
      "1069: 2.500000%\n",
      "1070: 2.736111%\n",
      "1071: 6.958333%\n",
      "1072: 5.273504%\n",
      "1073: 2.666667%\n",
      "1074: 1.125000%\n",
      "1075: 6.164377%\n",
      "1076: 8.339286%\n",
      "1077: 4.402778%\n",
      "1078: 4.404762%\n",
      "1079: 7.936508%\n",
      "1080: 1.750000%\n",
      "1081: 2.565171%\n",
      "1082: 3.936508%\n",
      "1083: 2.380952%\n",
      "1084: 2.909091%\n",
      "1085: 4.839286%\n",
      "1086: 3.717949%\n",
      "1087: 6.757631%\n",
      "1088: 8.321123%\n",
      "1089: 1.098901%\n",
      "1090: 2.083333%\n",
      "1091: 3.380342%\n",
      "1092: 7.797619%\n",
      "1093: 5.801587%\n",
      "1094: 7.404332%\n",
      "1095: 3.051282%\n",
      "1096: 2.250000%\n",
      "1097: 3.958333%\n",
      "1098: 4.273504%\n",
      "1099: 4.513889%\n",
      "1100: 2.708333%\n",
      "1101: 3.121212%\n",
      "1102: 6.705739%\n",
      "1103: 7.944444%\n",
      "1104: 7.555556%\n",
      "1105: 1.250000%\n",
      "1106: 3.492063%\n",
      "1107: 3.023810%\n",
      "1108: 7.111111%\n",
      "1109: 3.135989%\n",
      "1110: 3.454545%\n",
      "1111: 3.222222%\n",
      "1112: 6.775794%\n",
      "1113: 2.291667%\n",
      "1114: 0.625000%\n",
      "1115: 1.168831%\n",
      "1116: 3.940171%\n",
      "1117: 1.488095%\n",
      "1118: 3.255952%\n",
      "1119: 1.000000%\n",
      "1120: 6.714286%\n",
      "1121: 2.847222%\n",
      "1122: 6.408730%\n",
      "1123: 6.865079%\n",
      "1124: 2.658730%\n",
      "1125: 2.000000%\n",
      "1126: 1.848776%\n",
      "1127: 6.371212%\n",
      "1128: 3.055556%\n",
      "1129: 1.384615%\n",
      "Test error: 7.828107%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for index, batch in enumerate(batches):\n",
    "        batch_data = batch[0]\n",
    "        batch_target = batch[1]\n",
    "    \n",
    "        epoch = batch[2]\n",
    "\n",
    "        if epoch >= epochs:\n",
    "            break\n",
    "        \n",
    "        feed = {X: batch_data, y: batch_target}\n",
    "        train_error, _ = sess.run([error, optimize], feed)\n",
    "        \n",
    "        print('{}: {:3.6f}%'.format(index + 1, 100 * train_error))\n",
    "\n",
    "    test_feed = {X: test_data, y: test_target}\n",
    "    test_error, _ = sess.run([error, optimize], test_feed)\n",
    "    \n",
    "    print('Test error: {:3.6f}%'.format(100 * test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bi-directional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_output, _ = tf.nn.bidirectional_dynamic_rnn(tf.nn.rnn_cell.GRUCell(num_neurons), \n",
    "                                            tf.nn.rnn_cell.GRUCell(num_neurons),\n",
    "                                            X,\n",
    "                                            dtype=tf.float64, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'bidirectional_rnn/fw/fw/transpose_1:0' shape=(?, 14, 300) dtype=float64>,\n",
       " <tf.Tensor 'ReverseSequence:0' shape=(?, 14, 300) dtype=float64>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_output = tf.concat([new_output[0], new_output[1]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(600)])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_weight = tf.Variable(tf.truncated_normal([num_neurons * 2, num_classes], stddev=0.01, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_bias = tf.Variable(tf.constant(0.1, shape=[num_classes], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_flattened_output = tf.reshape(new_output, [-1, num_neurons * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_3:0' shape=(?, 600) dtype=float64>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_flattened_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_logits = tf.matmul(new_flattened_output, new_weight) + new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_logits_reshaped = tf.reshape(new_logits, [-1, num_steps, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=new_logits, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_loss = tf.reduce_mean(new_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_mistakes = tf.not_equal(\n",
    "            tf.argmax(y, 2), tf.argmax(new_logits_reshaped, 2))\n",
    "new_mistakes = tf.cast(new_mistakes, tf.float64)\n",
    "new_mask = tf.sign(tf.reduce_max(tf.abs(y), reduction_indices=2))\n",
    "new_mistakes *= new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_mistakes = tf.reduce_sum(new_mistakes, reduction_indices=1)\n",
    "new_mistakes /= tf.cast(sequence_length, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_error = tf.reduce_mean(new_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_optimizer = tf.train.RMSPropOptimizer(0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_gradient = new_optimizer.compute_gradients(new_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_optimize = new_optimizer.apply_gradients(new_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_batch_size = 10\n",
    "new_batches = batched(train_data, train_target, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 94.835317%\n",
      "2: 95.771645%\n",
      "3: 95.962302%\n",
      "4: 97.083333%\n",
      "5: 97.833333%\n",
      "6: 94.634921%\n",
      "7: 96.754274%\n",
      "8: 96.234432%\n",
      "9: 96.709957%\n",
      "10: 90.875000%\n",
      "11: 95.105284%\n",
      "12: 96.291667%\n",
      "13: 94.428571%\n",
      "14: 91.462121%\n",
      "15: 97.934343%\n",
      "16: 98.276099%\n",
      "17: 95.279762%\n",
      "18: 95.307540%\n",
      "19: 97.355284%\n",
      "20: 94.527778%\n",
      "21: 94.535714%\n",
      "22: 94.962302%\n",
      "23: 93.702325%\n",
      "24: 94.734127%\n",
      "25: 91.563617%\n",
      "26: 95.684524%\n",
      "27: 94.494172%\n",
      "28: 93.122835%\n",
      "29: 93.227994%\n",
      "30: 91.396825%\n",
      "31: 93.168651%\n",
      "32: 95.512210%\n",
      "33: 97.021645%\n",
      "34: 89.133547%\n",
      "35: 87.401709%\n",
      "36: 90.138889%\n",
      "37: 90.149725%\n",
      "38: 85.769300%\n",
      "39: 91.716270%\n",
      "40: 89.998321%\n",
      "41: 91.791667%\n",
      "42: 93.797924%\n",
      "43: 86.864899%\n",
      "44: 96.720058%\n",
      "45: 85.143939%\n",
      "46: 90.830808%\n",
      "47: 85.748876%\n",
      "48: 87.949023%\n",
      "49: 88.696429%\n",
      "50: 88.022145%\n",
      "51: 89.785354%\n",
      "52: 88.344475%\n",
      "53: 82.385226%\n",
      "54: 86.859127%\n",
      "55: 87.028208%\n",
      "56: 83.237734%\n",
      "57: 86.271465%\n",
      "58: 88.228244%\n",
      "59: 76.482087%\n",
      "60: 93.111361%\n",
      "61: 83.587302%\n",
      "62: 87.428460%\n",
      "63: 78.310440%\n",
      "64: 84.064560%\n",
      "65: 81.557540%\n",
      "66: 82.932179%\n",
      "67: 84.621129%\n",
      "68: 82.552503%\n",
      "69: 79.112943%\n",
      "70: 89.286394%\n",
      "71: 78.152486%\n",
      "72: 78.865454%\n",
      "73: 93.444444%\n",
      "74: 84.315476%\n",
      "75: 84.868506%\n",
      "76: 81.207875%\n",
      "77: 81.309163%\n",
      "78: 86.308622%\n",
      "79: 84.832431%\n",
      "80: 89.569028%\n",
      "81: 85.350830%\n",
      "82: 88.764139%\n",
      "83: 86.508492%\n",
      "84: 92.579365%\n",
      "85: 86.099817%\n",
      "86: 80.222902%\n",
      "87: 79.091991%\n",
      "88: 88.467172%\n",
      "89: 88.500805%\n",
      "90: 78.065018%\n",
      "91: 81.162157%\n",
      "92: 79.172411%\n",
      "93: 78.747253%\n",
      "94: 84.144689%\n",
      "95: 77.517857%\n",
      "96: 81.335567%\n",
      "97: 79.223138%\n",
      "98: 84.172466%\n",
      "99: 84.947330%\n",
      "100: 74.304792%\n",
      "101: 81.133852%\n",
      "102: 75.973846%\n",
      "103: 79.709235%\n",
      "104: 77.698690%\n",
      "105: 78.982448%\n",
      "106: 77.128968%\n",
      "107: 77.978549%\n",
      "108: 76.799978%\n",
      "109: 76.958708%\n",
      "110: 73.230131%\n",
      "111: 77.738345%\n",
      "112: 70.414141%\n",
      "113: 84.407426%\n",
      "114: 82.786394%\n",
      "115: 83.085872%\n",
      "116: 72.108586%\n",
      "117: 80.077381%\n",
      "118: 80.756563%\n",
      "119: 82.103730%\n",
      "120: 68.963745%\n",
      "121: 73.936508%\n",
      "122: 68.270396%\n",
      "123: 79.254218%\n",
      "124: 69.664141%\n",
      "125: 73.220085%\n",
      "126: 78.297688%\n",
      "127: 79.410714%\n",
      "128: 77.592643%\n",
      "129: 73.468032%\n",
      "130: 68.529429%\n",
      "131: 65.076840%\n",
      "132: 69.454365%\n",
      "133: 71.766858%\n",
      "134: 69.839896%\n",
      "135: 69.217990%\n",
      "136: 71.904762%\n",
      "137: 67.950855%\n",
      "138: 70.928030%\n",
      "139: 69.975649%\n",
      "140: 70.723291%\n",
      "141: 59.799756%\n",
      "142: 70.378205%\n",
      "143: 68.181277%\n",
      "144: 65.356269%\n",
      "145: 63.976870%\n",
      "146: 63.854437%\n",
      "147: 61.911214%\n",
      "148: 56.174964%\n",
      "149: 63.197691%\n",
      "150: 71.210761%\n",
      "151: 64.501443%\n",
      "152: 55.415584%\n",
      "153: 64.483586%\n",
      "154: 52.474165%\n",
      "155: 63.464591%\n",
      "156: 59.128247%\n",
      "157: 52.554654%\n",
      "158: 58.641803%\n",
      "159: 47.835317%\n",
      "160: 52.370990%\n",
      "161: 55.815587%\n",
      "162: 51.944625%\n",
      "163: 52.408272%\n",
      "164: 46.450660%\n",
      "165: 42.218171%\n",
      "166: 54.126832%\n",
      "167: 47.438825%\n",
      "168: 46.506771%\n",
      "169: 41.392857%\n",
      "170: 47.557498%\n",
      "171: 45.752442%\n",
      "172: 50.890873%\n",
      "173: 42.206696%\n",
      "174: 36.075619%\n",
      "175: 38.021839%\n",
      "176: 39.084596%\n",
      "177: 42.175658%\n",
      "178: 36.756466%\n",
      "179: 36.406136%\n",
      "180: 28.586691%\n",
      "181: 39.676129%\n",
      "182: 36.120768%\n",
      "183: 26.345044%\n",
      "184: 37.609141%\n",
      "185: 32.010226%\n",
      "186: 35.424950%\n",
      "187: 35.757867%\n",
      "188: 30.322969%\n",
      "189: 43.920066%\n",
      "190: 32.737374%\n",
      "191: 38.903541%\n",
      "192: 29.539974%\n",
      "193: 32.082418%\n",
      "194: 31.426643%\n",
      "195: 36.162698%\n",
      "196: 22.781136%\n",
      "197: 19.110653%\n",
      "198: 28.996573%\n",
      "199: 31.327978%\n",
      "200: 21.448107%\n",
      "201: 34.919192%\n",
      "202: 34.661033%\n",
      "203: 35.866911%\n",
      "204: 31.546176%\n",
      "205: 29.299603%\n",
      "206: 32.532329%\n",
      "207: 35.881410%\n",
      "208: 32.337302%\n",
      "209: 28.619436%\n",
      "210: 27.290945%\n",
      "211: 25.603175%\n",
      "212: 26.404762%\n",
      "213: 23.816378%\n",
      "214: 24.761003%\n",
      "215: 25.793984%\n",
      "216: 21.333791%\n",
      "217: 25.263889%\n",
      "218: 22.688187%\n",
      "219: 20.060592%\n",
      "220: 21.489621%\n",
      "221: 15.526557%\n",
      "222: 22.263584%\n",
      "223: 31.465188%\n",
      "224: 25.320208%\n",
      "225: 13.710317%\n",
      "226: 22.386516%\n",
      "227: 19.284327%\n",
      "228: 19.774725%\n",
      "229: 12.246392%\n",
      "230: 25.523366%\n",
      "231: 20.591145%\n",
      "232: 26.829726%\n",
      "233: 12.604243%\n",
      "234: 13.336871%\n",
      "235: 19.444444%\n",
      "236: 15.364469%\n",
      "237: 22.204545%\n",
      "238: 15.428571%\n",
      "239: 15.036131%\n",
      "240: 14.918651%\n",
      "241: 8.179029%\n",
      "242: 20.261294%\n",
      "243: 17.288475%\n",
      "244: 15.055556%\n",
      "245: 22.761447%\n",
      "246: 26.923993%\n",
      "247: 19.465659%\n",
      "248: 20.982143%\n",
      "249: 8.678807%\n",
      "250: 17.318834%\n",
      "251: 13.339286%\n",
      "252: 19.906496%\n",
      "253: 21.055556%\n",
      "254: 32.597985%\n",
      "255: 17.025294%\n",
      "256: 18.134615%\n",
      "257: 6.035465%\n",
      "258: 27.987360%\n",
      "259: 14.904942%\n",
      "260: 19.258478%\n",
      "261: 15.665016%\n",
      "262: 23.511655%\n",
      "263: 18.154762%\n",
      "264: 12.518926%\n",
      "265: 9.876679%\n",
      "266: 11.541306%\n",
      "267: 18.322747%\n",
      "268: 16.868742%\n",
      "269: 11.563853%\n",
      "270: 16.871323%\n",
      "271: 9.239954%\n",
      "272: 13.527473%\n",
      "273: 19.569444%\n",
      "274: 7.604853%\n",
      "275: 11.130952%\n",
      "276: 15.876984%\n",
      "277: 11.594697%\n",
      "278: 8.707126%\n",
      "279: 14.734182%\n",
      "280: 14.233086%\n",
      "281: 11.621753%\n",
      "282: 9.922619%\n",
      "283: 11.835317%\n",
      "284: 8.674659%\n",
      "285: 12.330739%\n",
      "286: 12.478175%\n",
      "287: 15.940171%\n",
      "288: 21.201160%\n",
      "289: 10.317460%\n",
      "290: 12.704545%\n",
      "291: 17.335775%\n",
      "292: 9.456890%\n",
      "293: 19.466270%\n",
      "294: 7.669192%\n",
      "295: 12.297494%\n",
      "296: 12.670330%\n",
      "297: 8.949106%\n",
      "298: 7.750000%\n",
      "299: 7.041667%\n",
      "300: 17.094628%\n",
      "301: 11.904637%\n",
      "302: 11.656746%\n",
      "303: 5.589286%\n",
      "304: 8.537393%\n",
      "305: 6.636905%\n",
      "306: 5.406746%\n",
      "307: 14.619755%\n",
      "308: 8.197802%\n",
      "309: 5.751679%\n",
      "310: 10.952381%\n",
      "311: 8.842949%\n",
      "312: 10.633117%\n",
      "313: 11.636780%\n",
      "314: 12.311050%\n",
      "315: 13.098485%\n",
      "316: 17.567100%\n",
      "317: 10.290751%\n",
      "318: 3.342949%\n",
      "319: 7.295996%\n",
      "320: 9.285714%\n",
      "321: 4.880952%\n",
      "322: 4.916667%\n",
      "323: 10.218434%\n",
      "324: 20.132812%\n",
      "325: 8.618742%\n",
      "326: 4.900488%\n",
      "327: 13.088370%\n",
      "328: 9.909812%\n",
      "329: 10.138889%\n",
      "330: 6.706349%\n",
      "331: 2.852564%\n",
      "332: 13.071429%\n",
      "333: 13.890929%\n",
      "334: 9.383450%\n",
      "335: 9.961039%\n",
      "336: 16.150183%\n",
      "337: 6.683913%\n",
      "338: 20.903860%\n",
      "339: 16.863636%\n",
      "340: 14.757812%\n",
      "341: 12.391567%\n",
      "342: 9.246032%\n",
      "343: 10.450688%\n",
      "344: 2.956349%\n",
      "345: 6.100635%\n",
      "346: 9.804029%\n",
      "347: 3.446429%\n",
      "348: 4.797494%\n",
      "349: 5.214646%\n",
      "350: 5.277778%\n",
      "351: 6.674784%\n",
      "352: 7.403846%\n",
      "353: 9.675325%\n",
      "354: 6.049784%\n",
      "355: 14.057234%\n",
      "356: 10.827922%\n",
      "357: 6.167735%\n",
      "358: 7.051587%\n",
      "359: 8.476912%\n",
      "360: 9.345238%\n",
      "361: 5.130647%\n",
      "362: 14.875000%\n",
      "363: 12.561688%\n",
      "364: 7.553571%\n",
      "365: 3.561508%\n",
      "366: 11.277778%\n",
      "367: 14.236111%\n",
      "368: 13.264957%\n",
      "369: 15.555556%\n",
      "370: 3.428932%\n",
      "371: 11.557540%\n",
      "372: 7.740260%\n",
      "373: 2.214286%\n",
      "374: 3.801587%\n",
      "375: 3.293651%\n",
      "376: 5.857143%\n",
      "377: 8.902778%\n",
      "378: 3.888889%\n",
      "379: 2.519841%\n",
      "380: 6.861111%\n",
      "381: 16.586081%\n",
      "382: 2.450397%\n",
      "383: 7.403846%\n",
      "384: 4.583333%\n",
      "385: 4.236111%\n",
      "386: 6.436508%\n",
      "387: 6.297619%\n",
      "388: 6.968254%\n",
      "389: 0.773810%\n",
      "390: 9.291667%\n",
      "391: 8.811508%\n",
      "392: 11.428571%\n",
      "393: 9.051282%\n",
      "394: 2.222222%\n",
      "395: 8.125000%\n",
      "396: 4.345238%\n",
      "397: 16.821429%\n",
      "398: 4.621212%\n",
      "399: 8.555556%\n",
      "400: 11.496032%\n",
      "401: 12.916667%\n",
      "402: 7.743923%\n",
      "403: 7.692641%\n",
      "404: 2.725275%\n",
      "405: 6.636003%\n",
      "406: 5.027473%\n",
      "407: 1.394716%\n",
      "408: 6.973304%\n",
      "409: 4.206349%\n",
      "410: 12.593434%\n",
      "411: 4.317918%\n",
      "412: 2.418831%\n",
      "413: 5.720238%\n",
      "414: 6.485681%\n",
      "415: 3.658425%\n",
      "416: 5.220238%\n",
      "417: 3.277778%\n",
      "418: 3.680556%\n",
      "419: 2.125000%\n",
      "420: 4.237790%\n",
      "421: 3.611111%\n",
      "422: 3.717949%\n",
      "423: 2.055556%\n",
      "424: 5.000000%\n",
      "425: 3.527778%\n",
      "426: 3.527473%\n",
      "427: 3.059524%\n",
      "428: 3.416667%\n",
      "429: 1.842949%\n",
      "430: 10.371032%\n",
      "431: 4.984127%\n",
      "432: 5.638889%\n",
      "433: 3.690476%\n",
      "434: 7.238636%\n",
      "435: 4.553447%\n",
      "436: 9.958333%\n",
      "437: 6.141636%\n",
      "438: 5.416667%\n",
      "439: 3.055556%\n",
      "440: 1.250000%\n",
      "441: 7.797619%\n",
      "442: 5.857143%\n",
      "443: 5.625000%\n",
      "444: 4.502165%\n",
      "445: 3.585859%\n",
      "446: 9.992063%\n",
      "447: 9.498557%\n",
      "448: 3.625000%\n",
      "449: 1.287879%\n",
      "450: 7.817460%\n",
      "451: 5.773504%\n",
      "452: 1.079545%\n",
      "453: 2.666667%\n",
      "454: 2.857143%\n",
      "455: 2.847222%\n",
      "456: 0.625000%\n",
      "457: 0.000000%\n",
      "458: 10.000000%\n",
      "459: 2.291667%\n",
      "460: 2.291667%\n",
      "461: 2.222222%\n",
      "462: 2.159091%\n",
      "463: 5.833333%\n",
      "464: 5.208333%\n",
      "465: 1.009615%\n",
      "466: 5.912698%\n",
      "467: 3.750000%\n",
      "468: 0.384615%\n",
      "469: 0.000000%\n",
      "470: 4.583333%\n",
      "471: 3.500000%\n",
      "472: 2.797619%\n",
      "473: 2.051282%\n",
      "474: 3.333333%\n",
      "475: 1.333333%\n",
      "476: 0.555556%\n",
      "477: 1.125000%\n",
      "478: 2.041667%\n",
      "479: 5.479853%\n",
      "480: 2.454545%\n",
      "481: 4.741758%\n",
      "482: 1.932234%\n",
      "483: 1.000000%\n",
      "484: 4.327922%\n",
      "485: 7.287879%\n",
      "486: 1.666667%\n",
      "487: 1.509615%\n",
      "488: 0.555556%\n",
      "489: 3.777778%\n",
      "490: 1.666667%\n",
      "491: 4.117063%\n",
      "492: 4.484127%\n",
      "493: 3.166667%\n",
      "494: 4.107143%\n",
      "495: 7.539683%\n",
      "496: 3.261905%\n",
      "497: 3.311688%\n",
      "498: 6.833333%\n",
      "499: 3.246212%\n",
      "500: 4.444444%\n",
      "501: 3.063672%\n",
      "502: 8.777778%\n",
      "503: 0.000000%\n",
      "504: 3.531746%\n",
      "505: 0.500000%\n",
      "506: 8.500000%\n",
      "507: 2.916667%\n",
      "508: 1.634615%\n",
      "509: 3.055556%\n",
      "510: 4.404762%\n",
      "511: 7.297980%\n",
      "512: 5.000000%\n",
      "513: 3.333333%\n",
      "514: 7.287879%\n",
      "515: 1.666667%\n",
      "516: 8.888889%\n",
      "517: 2.777778%\n",
      "518: 0.454545%\n",
      "519: 1.250000%\n",
      "520: 1.666667%\n",
      "521: 1.214286%\n",
      "522: 0.555556%\n",
      "523: 3.995726%\n",
      "524: 1.555556%\n",
      "525: 1.287879%\n",
      "526: 0.357143%\n",
      "527: 3.121212%\n",
      "528: 0.833333%\n",
      "529: 9.500000%\n",
      "530: 4.047619%\n",
      "531: 0.000000%\n",
      "532: 7.380952%\n",
      "533: 0.500000%\n",
      "534: 1.130952%\n",
      "535: 0.000000%\n",
      "536: 2.666667%\n",
      "537: 0.454545%\n",
      "538: 0.714286%\n",
      "539: 1.666667%\n",
      "540: 3.333333%\n",
      "541: 1.180556%\n",
      "542: 1.666667%\n",
      "543: 0.000000%\n",
      "544: 5.333333%\n",
      "545: 4.523810%\n",
      "546: 2.607143%\n",
      "547: 3.466811%\n",
      "548: 4.387626%\n",
      "549: 3.809524%\n",
      "550: 3.530303%\n",
      "551: 1.995726%\n",
      "552: 5.454545%\n",
      "553: 3.561508%\n",
      "554: 0.000000%\n",
      "555: 2.038462%\n",
      "556: 1.180556%\n",
      "557: 0.555556%\n",
      "558: 0.000000%\n",
      "559: 1.555556%\n",
      "560: 0.384615%\n",
      "561: 0.384615%\n",
      "562: 1.000000%\n",
      "563: 3.333333%\n",
      "564: 6.666667%\n",
      "565: 3.333333%\n",
      "566: 1.098901%\n",
      "567: 2.916667%\n",
      "568: 1.666667%\n",
      "569: 0.000000%\n",
      "570: 0.000000%\n",
      "571: 0.000000%\n",
      "572: 1.555556%\n",
      "573: 1.388889%\n",
      "574: 0.500000%\n",
      "575: 0.000000%\n",
      "576: 2.777778%\n",
      "577: 2.666667%\n",
      "578: 4.791667%\n",
      "579: 1.125000%\n",
      "580: 0.500000%\n",
      "581: 0.500000%\n",
      "582: 2.000000%\n",
      "583: 1.666667%\n",
      "584: 0.625000%\n",
      "585: 3.121212%\n",
      "586: 3.490676%\n",
      "587: 3.720238%\n",
      "588: 6.666667%\n",
      "589: 4.888889%\n",
      "590: 1.250000%\n",
      "591: 4.433178%\n",
      "592: 1.111111%\n",
      "593: 2.416667%\n",
      "594: 1.241758%\n",
      "595: 0.909091%\n",
      "596: 1.555556%\n",
      "597: 0.000000%\n",
      "598: 0.000000%\n",
      "599: 2.666667%\n",
      "600: 0.500000%\n",
      "601: 2.000000%\n",
      "602: 0.384615%\n",
      "603: 9.140443%\n",
      "604: 4.311869%\n",
      "605: 5.714286%\n",
      "606: 0.000000%\n",
      "607: 3.666667%\n",
      "608: 1.666667%\n",
      "609: 0.000000%\n",
      "610: 2.047619%\n",
      "611: 2.597403%\n",
      "612: 5.357143%\n",
      "613: 1.388889%\n",
      "614: 0.625000%\n",
      "615: 0.833333%\n",
      "616: 3.214286%\n",
      "617: 4.047619%\n",
      "618: 2.833333%\n",
      "619: 4.888889%\n",
      "620: 1.666667%\n",
      "621: 2.000000%\n",
      "622: 3.333333%\n",
      "623: 0.625000%\n",
      "624: 3.956044%\n",
      "625: 0.454545%\n",
      "626: 2.551282%\n",
      "627: 2.163462%\n",
      "628: 1.666667%\n",
      "629: 0.000000%\n",
      "630: 0.000000%\n",
      "631: 1.071429%\n",
      "632: 4.166667%\n",
      "633: 1.666667%\n",
      "634: 2.000000%\n",
      "635: 6.611111%\n",
      "636: 0.714286%\n",
      "637: 7.625000%\n",
      "638: 1.547619%\n",
      "639: 0.833333%\n",
      "640: 1.055556%\n",
      "641: 5.555556%\n",
      "642: 1.388889%\n",
      "643: 0.000000%\n",
      "644: 0.000000%\n",
      "645: 1.398810%\n",
      "646: 1.818182%\n",
      "647: 6.250000%\n",
      "648: 1.666667%\n",
      "649: 0.833333%\n",
      "650: 0.357143%\n",
      "651: 1.125000%\n",
      "652: 0.357143%\n",
      "653: 0.912698%\n",
      "654: 3.888889%\n",
      "655: 0.000000%\n",
      "656: 0.555556%\n",
      "657: 1.111111%\n",
      "658: 1.845238%\n",
      "659: 2.857143%\n",
      "660: 1.666667%\n",
      "661: 1.666667%\n",
      "662: 1.833333%\n",
      "663: 3.888889%\n",
      "664: 4.242424%\n",
      "665: 4.285714%\n",
      "666: 1.555556%\n",
      "667: 0.625000%\n",
      "668: 3.291667%\n",
      "669: 0.833333%\n",
      "670: 4.291667%\n",
      "671: 2.500000%\n",
      "672: 0.000000%\n",
      "673: 3.055556%\n",
      "674: 0.555556%\n",
      "675: 5.396825%\n",
      "676: 1.666667%\n",
      "677: 1.250000%\n",
      "678: 0.000000%\n",
      "679: 0.833333%\n",
      "680: 0.416667%\n",
      "681: 0.000000%\n",
      "682: 0.000000%\n",
      "683: 0.000000%\n",
      "684: 0.000000%\n",
      "685: 0.000000%\n",
      "686: 3.333333%\n",
      "687: 3.333333%\n",
      "688: 3.333333%\n",
      "689: 0.000000%\n",
      "690: 0.000000%\n",
      "691: 1.000000%\n",
      "692: 0.000000%\n",
      "693: 0.000000%\n",
      "694: 0.000000%\n",
      "695: 0.000000%\n",
      "696: 0.625000%\n",
      "697: 1.153846%\n",
      "698: 0.769231%\n",
      "699: 0.000000%\n",
      "700: 0.000000%\n",
      "701: 0.000000%\n",
      "702: 0.000000%\n",
      "703: 0.000000%\n",
      "704: 0.000000%\n",
      "705: 0.000000%\n",
      "706: 3.333333%\n",
      "707: 0.000000%\n",
      "708: 1.666667%\n",
      "709: 0.000000%\n",
      "710: 0.555556%\n",
      "711: 2.575758%\n",
      "712: 0.000000%\n",
      "713: 0.000000%\n",
      "714: 0.940171%\n",
      "715: 0.416667%\n",
      "716: 1.666667%\n",
      "717: 0.000000%\n",
      "718: 0.384615%\n",
      "719: 1.666667%\n",
      "720: 0.000000%\n",
      "721: 0.000000%\n",
      "722: 0.714286%\n",
      "723: 0.000000%\n",
      "724: 0.000000%\n",
      "725: 1.666667%\n",
      "726: 0.000000%\n",
      "727: 0.000000%\n",
      "728: 0.416667%\n",
      "729: 0.000000%\n",
      "730: 0.000000%\n",
      "731: 0.000000%\n",
      "732: 2.579365%\n",
      "733: 0.000000%\n",
      "734: 3.333333%\n",
      "735: 1.666667%\n",
      "736: 0.454545%\n",
      "737: 2.083333%\n",
      "738: 0.000000%\n",
      "739: 0.000000%\n",
      "740: 4.166667%\n",
      "741: 0.000000%\n",
      "742: 0.000000%\n",
      "743: 0.357143%\n",
      "744: 0.454545%\n",
      "745: 0.000000%\n",
      "746: 0.000000%\n",
      "747: 0.000000%\n",
      "748: 0.357143%\n",
      "749: 0.000000%\n",
      "750: 0.000000%\n",
      "751: 1.666667%\n",
      "752: 0.000000%\n",
      "753: 0.000000%\n",
      "754: 1.666667%\n",
      "755: 5.000000%\n",
      "756: 0.833333%\n",
      "757: 0.555556%\n",
      "758: 0.000000%\n",
      "759: 3.333333%\n",
      "760: 1.666667%\n",
      "761: 0.000000%\n",
      "762: 0.000000%\n",
      "763: 0.555556%\n",
      "764: 0.555556%\n",
      "765: 1.666667%\n",
      "766: 0.000000%\n",
      "767: 0.000000%\n",
      "768: 0.625000%\n",
      "769: 0.000000%\n",
      "770: 1.666667%\n",
      "771: 0.000000%\n",
      "772: 0.000000%\n",
      "773: 0.555556%\n",
      "774: 0.000000%\n",
      "775: 0.000000%\n",
      "776: 0.000000%\n",
      "777: 0.357143%\n",
      "778: 0.555556%\n",
      "779: 0.000000%\n",
      "780: 5.625000%\n",
      "781: 5.000000%\n",
      "782: 0.000000%\n",
      "783: 2.458333%\n",
      "784: 0.000000%\n",
      "785: 1.666667%\n",
      "786: 0.000000%\n",
      "787: 0.000000%\n",
      "788: 0.500000%\n",
      "789: 0.555556%\n",
      "790: 1.000000%\n",
      "791: 0.000000%\n",
      "792: 0.625000%\n",
      "793: 0.000000%\n",
      "794: 0.714286%\n",
      "795: 5.833333%\n",
      "796: 2.291667%\n",
      "797: 0.000000%\n",
      "798: 0.500000%\n",
      "799: 1.555556%\n",
      "800: 0.625000%\n",
      "801: 6.428571%\n",
      "802: 1.000000%\n",
      "803: 0.000000%\n",
      "804: 0.000000%\n",
      "805: 0.500000%\n",
      "806: 0.000000%\n",
      "807: 2.121212%\n",
      "808: 0.454545%\n",
      "809: 0.000000%\n",
      "810: 3.333333%\n",
      "811: 0.000000%\n",
      "812: 0.909091%\n",
      "813: 1.666667%\n",
      "814: 2.791667%\n",
      "815: 2.051282%\n",
      "816: 0.416667%\n",
      "817: 0.909091%\n",
      "818: 0.833333%\n",
      "819: 0.714286%\n",
      "820: 1.555556%\n",
      "821: 0.833333%\n",
      "822: 0.000000%\n",
      "823: 0.000000%\n",
      "824: 0.625000%\n",
      "825: 1.666667%\n",
      "826: 0.000000%\n",
      "827: 0.625000%\n",
      "828: 0.833333%\n",
      "829: 0.357143%\n",
      "830: 0.000000%\n",
      "831: 4.666667%\n",
      "832: 0.000000%\n",
      "833: 2.013889%\n",
      "834: 0.384615%\n",
      "835: 0.000000%\n",
      "836: 4.111111%\n",
      "837: 0.714286%\n",
      "838: 1.666667%\n",
      "839: 0.000000%\n",
      "840: 0.000000%\n",
      "841: 1.547619%\n",
      "842: 1.287879%\n",
      "843: 0.454545%\n",
      "844: 0.000000%\n",
      "845: 0.000000%\n",
      "846: 2.222222%\n",
      "847: 1.428571%\n",
      "848: 5.000000%\n",
      "849: 1.666667%\n",
      "850: 0.000000%\n",
      "851: 2.847222%\n",
      "852: 1.666667%\n",
      "853: 1.666667%\n",
      "854: 1.250000%\n",
      "855: 0.000000%\n",
      "856: 0.000000%\n",
      "857: 1.666667%\n",
      "858: 0.000000%\n",
      "859: 0.000000%\n",
      "860: 0.000000%\n",
      "861: 1.666667%\n",
      "862: 3.333333%\n",
      "863: 0.555556%\n",
      "864: 2.458333%\n",
      "865: 3.000000%\n",
      "866: 0.000000%\n",
      "867: 0.000000%\n",
      "868: 0.833333%\n",
      "869: 4.000000%\n",
      "870: 0.833333%\n",
      "871: 3.888889%\n",
      "872: 5.000000%\n",
      "873: 0.000000%\n",
      "874: 1.666667%\n",
      "875: 0.000000%\n",
      "876: 1.000000%\n",
      "877: 0.000000%\n",
      "878: 0.000000%\n",
      "879: 0.555556%\n",
      "880: 0.000000%\n",
      "881: 0.000000%\n",
      "882: 0.000000%\n",
      "883: 2.162698%\n",
      "884: 0.000000%\n",
      "885: 1.666667%\n",
      "886: 0.000000%\n",
      "887: 1.666667%\n",
      "888: 0.000000%\n",
      "889: 0.555556%\n",
      "890: 0.555556%\n",
      "891: 2.023810%\n",
      "892: 0.000000%\n",
      "893: 0.000000%\n",
      "894: 0.714286%\n",
      "895: 0.555556%\n",
      "896: 0.000000%\n",
      "897: 1.333333%\n",
      "898: 0.000000%\n",
      "899: 2.261905%\n",
      "900: 3.333333%\n",
      "901: 1.555556%\n",
      "902: 3.833333%\n",
      "903: 0.000000%\n",
      "904: 0.000000%\n",
      "905: 0.555556%\n",
      "906: 0.000000%\n",
      "907: 0.000000%\n",
      "908: 0.000000%\n",
      "909: 0.000000%\n",
      "910: 0.000000%\n",
      "911: 0.000000%\n",
      "912: 1.666667%\n",
      "913: 0.000000%\n",
      "914: 0.000000%\n",
      "915: 0.000000%\n",
      "916: 0.000000%\n",
      "917: 0.000000%\n",
      "918: 1.666667%\n",
      "919: 0.972222%\n",
      "920: 0.000000%\n",
      "921: 0.000000%\n",
      "922: 0.000000%\n",
      "923: 0.000000%\n",
      "924: 0.000000%\n",
      "925: 0.000000%\n",
      "926: 0.000000%\n",
      "927: 0.000000%\n",
      "928: 0.000000%\n",
      "929: 0.833333%\n",
      "930: 0.000000%\n",
      "931: 0.000000%\n",
      "932: 0.625000%\n",
      "933: 0.000000%\n",
      "934: 0.000000%\n",
      "935: 0.000000%\n",
      "936: 0.000000%\n",
      "937: 0.000000%\n",
      "938: 0.000000%\n",
      "939: 0.000000%\n",
      "940: 0.000000%\n",
      "941: 0.000000%\n",
      "942: 0.000000%\n",
      "943: 0.000000%\n",
      "944: 0.000000%\n",
      "945: 1.666667%\n",
      "946: 0.000000%\n",
      "947: 0.000000%\n",
      "948: 0.000000%\n",
      "949: 0.000000%\n",
      "950: 0.000000%\n",
      "951: 0.000000%\n",
      "952: 0.000000%\n",
      "953: 0.000000%\n",
      "954: 0.555556%\n",
      "955: 0.000000%\n",
      "956: 0.000000%\n",
      "957: 0.000000%\n",
      "958: 1.250000%\n",
      "959: 0.000000%\n",
      "960: 0.000000%\n",
      "961: 0.000000%\n",
      "962: 0.000000%\n",
      "963: 0.416667%\n",
      "964: 0.000000%\n",
      "965: 0.000000%\n",
      "966: 0.357143%\n",
      "967: 0.000000%\n",
      "968: 0.500000%\n",
      "969: 0.000000%\n",
      "970: 0.000000%\n",
      "971: 0.000000%\n",
      "972: 0.454545%\n",
      "973: 0.000000%\n",
      "974: 0.000000%\n",
      "975: 1.666667%\n",
      "976: 0.000000%\n",
      "977: 0.833333%\n",
      "978: 1.883117%\n",
      "979: 1.500000%\n",
      "980: 0.625000%\n",
      "981: 0.000000%\n",
      "982: 0.625000%\n",
      "983: 0.000000%\n",
      "984: 0.000000%\n",
      "985: 0.000000%\n",
      "986: 1.666667%\n",
      "987: 0.000000%\n",
      "988: 0.000000%\n",
      "989: 0.000000%\n",
      "990: 0.000000%\n",
      "991: 0.000000%\n",
      "992: 1.000000%\n",
      "993: 0.555556%\n",
      "994: 0.000000%\n",
      "995: 0.000000%\n",
      "996: 0.000000%\n",
      "997: 0.000000%\n",
      "998: 0.000000%\n",
      "999: 0.000000%\n",
      "1000: 0.000000%\n",
      "1001: 3.333333%\n",
      "1002: 0.000000%\n",
      "1003: 0.000000%\n",
      "1004: 0.000000%\n",
      "1005: 0.000000%\n",
      "1006: 0.000000%\n",
      "1007: 0.000000%\n",
      "1008: 0.000000%\n",
      "1009: 0.000000%\n",
      "1010: 0.000000%\n",
      "1011: 0.000000%\n",
      "1012: 0.000000%\n",
      "1013: 0.000000%\n",
      "1014: 0.000000%\n",
      "1015: 0.000000%\n",
      "1016: 1.666667%\n",
      "1017: 0.000000%\n",
      "1018: 0.000000%\n",
      "1019: 0.000000%\n",
      "1020: 0.000000%\n",
      "1021: 1.666667%\n",
      "1022: 0.000000%\n",
      "1023: 0.000000%\n",
      "1024: 0.000000%\n",
      "1025: 0.000000%\n",
      "1026: 0.000000%\n",
      "1027: 0.000000%\n",
      "1028: 0.000000%\n",
      "1029: 1.666667%\n",
      "1030: 0.833333%\n",
      "1031: 0.000000%\n",
      "1032: 0.000000%\n",
      "1033: 0.555556%\n",
      "1034: 1.130952%\n",
      "1035: 0.000000%\n",
      "1036: 0.000000%\n",
      "1037: 0.000000%\n",
      "1038: 0.000000%\n",
      "1039: 0.000000%\n",
      "1040: 0.000000%\n",
      "1041: 0.000000%\n",
      "1042: 2.000000%\n",
      "1043: 5.000000%\n",
      "1044: 0.000000%\n",
      "1045: 1.079545%\n",
      "1046: 0.000000%\n",
      "1047: 0.000000%\n",
      "1048: 1.000000%\n",
      "1049: 0.000000%\n",
      "1050: 0.000000%\n",
      "1051: 0.000000%\n",
      "1052: 0.000000%\n",
      "1053: 0.000000%\n",
      "1054: 1.666667%\n",
      "1055: 1.666667%\n",
      "1056: 0.000000%\n",
      "1057: 0.625000%\n",
      "1058: 0.000000%\n",
      "1059: 0.000000%\n",
      "1060: 0.000000%\n",
      "1061: 0.000000%\n",
      "1062: 0.000000%\n",
      "1063: 0.000000%\n",
      "1064: 0.000000%\n",
      "1065: 0.000000%\n",
      "1066: 1.666667%\n",
      "1067: 0.000000%\n",
      "1068: 0.000000%\n",
      "1069: 0.000000%\n",
      "1070: 0.000000%\n",
      "1071: 0.000000%\n",
      "1072: 0.000000%\n",
      "1073: 0.000000%\n",
      "1074: 0.000000%\n",
      "1075: 0.000000%\n",
      "1076: 0.000000%\n",
      "1077: 0.000000%\n",
      "1078: 1.666667%\n",
      "1079: 0.000000%\n",
      "1080: 0.000000%\n",
      "1081: 3.333333%\n",
      "1082: 0.000000%\n",
      "1083: 0.384615%\n",
      "1084: 0.000000%\n",
      "1085: 0.000000%\n",
      "1086: 0.000000%\n",
      "1087: 0.000000%\n",
      "1088: 0.000000%\n",
      "1089: 0.000000%\n",
      "1090: 0.500000%\n",
      "1091: 1.666667%\n",
      "1092: 0.000000%\n",
      "1093: 0.000000%\n",
      "1094: 3.333333%\n",
      "1095: 0.000000%\n",
      "1096: 0.000000%\n",
      "1097: 0.000000%\n",
      "1098: 0.000000%\n",
      "1099: 1.666667%\n",
      "1100: 0.000000%\n",
      "1101: 0.357143%\n",
      "1102: 0.555556%\n",
      "1103: 0.000000%\n",
      "1104: 0.000000%\n",
      "1105: 0.000000%\n",
      "1106: 0.000000%\n",
      "1107: 0.555556%\n",
      "1108: 0.000000%\n",
      "1109: 0.000000%\n",
      "1110: 0.000000%\n",
      "1111: 0.000000%\n",
      "1112: 0.839161%\n",
      "1113: 0.000000%\n",
      "1114: 0.000000%\n",
      "1115: 0.000000%\n",
      "1116: 0.000000%\n",
      "1117: 0.000000%\n",
      "1118: 0.000000%\n",
      "1119: 0.555556%\n",
      "1120: 0.000000%\n",
      "1121: 0.000000%\n",
      "1122: 0.833333%\n",
      "1123: 0.000000%\n",
      "1124: 0.555556%\n",
      "1125: 1.666667%\n",
      "1126: 0.000000%\n",
      "1127: 0.000000%\n",
      "1128: 0.000000%\n",
      "1129: 0.000000%\n",
      "Test error: 2.343834%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for index, batch in enumerate(new_batches):\n",
    "        batch_data = batch[0]\n",
    "        batch_target = batch[1]\n",
    "    \n",
    "        epoch = batch[2]\n",
    "\n",
    "        if epoch >= epochs:\n",
    "            break\n",
    "        \n",
    "        feed = {X: batch_data, y: batch_target}\n",
    "        train_error, _ = sess.run([new_error, new_optimize], feed)\n",
    "        \n",
    "        print('{}: {:3.6f}%'.format(index + 1, 100 * train_error))\n",
    "\n",
    "    test_feed = {X: test_data, y: test_target}\n",
    "    test_error, _ = sess.run([new_error, new_optimize], test_feed)\n",
    "    \n",
    "    print('Test error: {:3.6f}%'.format(100 * test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
